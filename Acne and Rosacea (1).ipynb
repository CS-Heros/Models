{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d0886c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32683383",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "buffer_size = 519\n",
    "batch_size = 16\n",
    "epochs = 500\n",
    "img_size = 224\n",
    "key = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a27297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1885 images belonging to 18 classes.\n",
      "Found 481 images belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('output/train/',\n",
    "                                                 target_size=(224,224),\n",
    "                                                 batch_size=16)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('output/val',\n",
    "                                            target_size=(224,224),\n",
    "                                            batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42240b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionResNetV2_model():\n",
    "\n",
    "    engine = tf.keras.applications.Xception(\n",
    "        # Freezing the weights of the top layer in the InceptionResNetV2 pre-traiined model\n",
    "        include_top = False,\n",
    "\n",
    "        # Use Imagenet weights\n",
    "        weights = 'imagenet',\n",
    "\n",
    "        # Define input shape to 224x224x3\n",
    "        input_shape = (img_size , img_size , 3),\n",
    "\n",
    "    )\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D(name = 'avg_pool')(engine.output)\n",
    "    x =Dropout(0.85)(x)\n",
    "    out = tf.keras.layers.Dense(key, activation = 'softmax', name = 'dense_output')(x)\n",
    "\n",
    "\n",
    "    # Build the Keras model\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = engine.input, outputs = out)\n",
    "    # Compile the model\n",
    "\n",
    "    model.compile(\n",
    "        # Set optimizer to Adam(0.0001)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate= 3e-4),\n",
    "        #optimizer= SGD(lr=3e-4, momentum=0.9),\n",
    "        # Set loss to binary crossentropy\n",
    "        #loss = tf.keras.losses.sparse_categorical_crossentropy,\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "        # Set metrics to accuracy\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73f22e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                                                            patience=2,\n",
    "                                                            verbose=2,\n",
    "                                                            factor=0.5,\n",
    "                                                            min_lr=0.00001)\n",
    "reduce_lr =  keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=3, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25d1c08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    time_start = time.time()\n",
    "    \n",
    "    model = InceptionResNetV2_model()\n",
    "    \n",
    "    model.summary()\n",
    "    history = model.fit(training_set, epochs= epochs , verbose = 2, validation_data = test_set,\n",
    "                       callbacks=[early_stopping, reduce_lr , learning_rate_reduction])\n",
    "    \n",
    "    \n",
    "\n",
    "    model.save_weights('layer22-wskindiseases1.h5')\n",
    "    model.save('layer22-skindiseases1.h5')\n",
    "    \n",
    "    print('Model saved.')\n",
    "    \n",
    "    time_end = time.time()\n",
    "    print('Training Time:', time_end - time_start)\n",
    "    print('\\n')\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a4cc6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    #test_labels = np.array(test_labels)\n",
    "\n",
    "    from tensorflow import keras\n",
    "    print('Testing:')\n",
    "    mod = InceptionResNetV2_model()\n",
    "    mod.load_weights('Layer22-wskindiseases1.h5')\n",
    "    mod.evaluate(test_set)\n",
    "    \n",
    "    #prob = mod.predict(test_set)\n",
    "    #predIdxs = np.argmax(prob, axis=1) \n",
    "\n",
    "\n",
    "    print('\\n')\n",
    "    #print(classification_report(test_set.labels, predIdxs,target_names = key, digits=5))\n",
    "    return predIdxs, prob, mod "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c658ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 111, 111, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 111, 111, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 109, 109, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 109, 109, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 109, 109, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 109, 109, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 109, 109, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 109, 109, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 109, 109, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 109, 109, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 55, 55, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 55, 55, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 55, 55, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 55, 55, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 55, 55, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 55, 55, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 55, 55, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 55, 55, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 55, 55, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 55, 55, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 28, 28, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 28, 28, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 28, 28, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 28, 28, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 28, 28, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 28, 28, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 14, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 14, 14, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 14, 14, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 14, 14, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 14, 14, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 14, 14, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 14, 14, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 14, 14, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 14, 14, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 14, 14, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 14, 14, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 14, 14, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 14, 14, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 14, 14, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 14, 14, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 14, 14, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 14, 14, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 14, 14, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 14, 14, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 14, 14, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 14, 14, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 14, 14, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 14, 14, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 14, 14, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 14, 14, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 14, 14, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 14, 14, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 14, 14, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 14, 14, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 14, 14, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 1024)   745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 7, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7, 7, 1024)   4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 7, 7, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 7, 7, 1536)   1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 7, 7, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 7, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 7, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 7, 7, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 7, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_output (Dense)            (None, 18)           36882       dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,898,362\n",
      "Trainable params: 20,843,834\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "118/118 - 64s - loss: 2.0671 - accuracy: 0.3798 - val_loss: 1.5083 - val_accuracy: 0.5759\n",
      "Epoch 2/500\n",
      "118/118 - 56s - loss: 1.1510 - accuracy: 0.6573 - val_loss: 0.9885 - val_accuracy: 0.6965\n",
      "Epoch 3/500\n",
      "118/118 - 56s - loss: 0.7636 - accuracy: 0.7655 - val_loss: 1.0398 - val_accuracy: 0.7422\n",
      "Epoch 4/500\n",
      "118/118 - 56s - loss: 0.5305 - accuracy: 0.8329 - val_loss: 0.8439 - val_accuracy: 0.8025\n",
      "Epoch 5/500\n",
      "118/118 - 56s - loss: 0.4258 - accuracy: 0.8727 - val_loss: 0.9264 - val_accuracy: 0.7692\n",
      "Epoch 6/500\n",
      "118/118 - 56s - loss: 0.3542 - accuracy: 0.8875 - val_loss: 0.7944 - val_accuracy: 0.7859\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "Epoch 7/500\n",
      "118/118 - 56s - loss: 0.2270 - accuracy: 0.9347 - val_loss: 0.6517 - val_accuracy: 0.8316\n",
      "Epoch 8/500\n",
      "118/118 - 57s - loss: 0.1518 - accuracy: 0.9533 - val_loss: 0.5540 - val_accuracy: 0.8607\n",
      "Epoch 9/500\n",
      "118/118 - 56s - loss: 0.1141 - accuracy: 0.9719 - val_loss: 0.5856 - val_accuracy: 0.8669\n",
      "Epoch 10/500\n",
      "118/118 - 56s - loss: 0.0994 - accuracy: 0.9735 - val_loss: 0.5924 - val_accuracy: 0.8565\n",
      "Epoch 11/500\n",
      "118/118 - 56s - loss: 0.0686 - accuracy: 0.9846 - val_loss: 0.5894 - val_accuracy: 0.8836\n",
      "Epoch 12/500\n",
      "118/118 - 57s - loss: 0.0416 - accuracy: 0.9942 - val_loss: 0.5662 - val_accuracy: 0.8836\n",
      "Epoch 13/500\n",
      "118/118 - 56s - loss: 0.0416 - accuracy: 0.9883 - val_loss: 0.6000 - val_accuracy: 0.8898\n",
      "Epoch 14/500\n",
      "118/118 - 57s - loss: 0.0399 - accuracy: 0.9920 - val_loss: 0.6253 - val_accuracy: 0.8857\n",
      "Epoch 15/500\n",
      "118/118 - 57s - loss: 0.0298 - accuracy: 0.9926 - val_loss: 0.5850 - val_accuracy: 0.8877\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.8750000890577212e-05.\n",
      "Epoch 16/500\n",
      "118/118 - 56s - loss: 0.0279 - accuracy: 0.9920 - val_loss: 0.6016 - val_accuracy: 0.8898\n",
      "Epoch 17/500\n",
      "118/118 - 57s - loss: 0.0245 - accuracy: 0.9952 - val_loss: 0.5990 - val_accuracy: 0.8898\n",
      "Epoch 18/500\n",
      "118/118 - 56s - loss: 0.0182 - accuracy: 0.9968 - val_loss: 0.5970 - val_accuracy: 0.8898\n",
      "Epoch 19/500\n",
      "118/118 - 57s - loss: 0.0204 - accuracy: 0.9968 - val_loss: 0.5915 - val_accuracy: 0.8898\n",
      "Epoch 20/500\n",
      "118/118 - 56s - loss: 0.0303 - accuracy: 0.9926 - val_loss: 0.5916 - val_accuracy: 0.8857\n",
      "Epoch 21/500\n",
      "118/118 - 56s - loss: 0.0237 - accuracy: 0.9963 - val_loss: 0.5876 - val_accuracy: 0.8877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laptop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n",
      "Training Time: 1196.1315298080444\n",
      "\n",
      "\n",
      "Testing:\n",
      "31/31 [==============================] - 4s 94ms/step - loss: 0.5876 - accuracy: 0.8877\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predIdxs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18364/3722579853.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#train_dataset, test_dataset = data_Preprocessing(train_dataset, test_dataset)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtrain_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mpredIdxs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#show_train_history(train_history, 'sparse_categorical_accuracy')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18364/4029042986.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m#print(classification_report(test_set.labels, predIdxs,target_names = key, digits=5))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpredIdxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'predIdxs' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    train_history = train() \n",
    "    predIdxs,prob,  model = test()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45bed61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2366 files belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "input_path = 'Acne and Rosacea/'\n",
    "train_data = image_dataset_from_directory(directory=input_path,\n",
    "                                          batch_size=16,\n",
    "                                          image_size=(224, 224))\n",
    "key = train_data.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5f13002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_directory():\n",
    "    data_filenames = []\n",
    "    data_labels = []\n",
    "    for i in range (len(key)):\n",
    "        for filename in os.listdir(input_path + key[i]):\n",
    "                data_filenames.append(input_path +key[i]+'/' + filename)\n",
    "                data_labels.append(i)\n",
    "  \n",
    "    return  data_filenames, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdbbb9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_tfrecord(train_filenames, train_labels):  # Generate TFRecord of training set \n",
    "    with tf.io.TFRecordWriter(test_tfrecord)as writer:\n",
    "        for filename, label in zip(train_filenames, train_labels):\n",
    "            image = open(filename, 'rb').read()\n",
    "\n",
    "            feature = {\n",
    "                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),  # img > Bytes\n",
    "                'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))  # label > Int\n",
    "            }\n",
    "\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc136ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_example(example_string):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "\n",
    "    feature_dict = tf.io.parse_single_example(example_string, feature_description)\n",
    "    feature_dict['image'] = tf.io.decode_png(feature_dict['image'], channels=3)\n",
    "    feature_dict['image'] = tf.image.resize(feature_dict['image'], [img_size, img_size]) / 255.0\n",
    "    return feature_dict['image'], feature_dict['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5886fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_dataset(test_tfrecord):\n",
    "    raw_test_dataset = tf.data.TFRecordDataset(test_tfrecord)\n",
    "    test_dataset = raw_test_dataset.map(_parse_example)\n",
    "\n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63c808e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_Preprocessing( test_dataset):\n",
    "    test_dataset = test_dataset.batch(batch_size)\n",
    "    test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return  test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8d76a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionResNetV2_model():\n",
    "\n",
    "    engine = tf.keras.applications.Xception(\n",
    "        # Freezing the weights of the top layer in the InceptionResNetV2 pre-traiined model\n",
    "        include_top = False,\n",
    "\n",
    "        # Use Imagenet weights\n",
    "        weights = 'imagenet',\n",
    "\n",
    "        # Define input shape to 224x224x3\n",
    "        input_shape = (img_size , img_size , 3),\n",
    "\n",
    "    )\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D(name = 'avg_pool')(engine.output)\n",
    "    x =Dropout(0.85)(x)\n",
    "    out = tf.keras.layers.Dense(len(key), activation = 'softmax', name = 'dense_output')(x)\n",
    "\n",
    "\n",
    "    # Build the Keras model\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = engine.input, outputs = out)\n",
    "    # Compile the model\n",
    "\n",
    "    model.compile(\n",
    "        # Set optimizer to Adam(0.0001)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate= 3e-4),\n",
    "        #optimizer= SGD(lr=0.0001, momentum=0.9),\n",
    "        # Set loss to binary crossentropy\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy,\n",
    "\n",
    "        # Set metrics to accuracy\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0363adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_labels):\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    from tensorflow import keras\n",
    "    print('Testing:')\n",
    "    mod = InceptionResNetV2_model()\n",
    "    mod.load_weights('layer22-wskindiseases1.h5')\n",
    "    mod.evaluate(test_dataset)\n",
    "    \n",
    "    prob = mod.predict(test_dataset)\n",
    "    predIdxs = np.argmax(prob, axis=1) \n",
    "\n",
    "\n",
    "    print('\\n')\n",
    "    print(classification_report(test_labels, predIdxs,target_names = key, digits=5))\n",
    "    return test_labels, predIdxs, prob, mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef30cce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:\n",
      "149/149 [==============================] - 20s 103ms/step - loss: 0.1219 - accuracy: 0.9748\n",
      "\n",
      "\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                    Acne    0.97426   0.98148   0.97786       270\n",
      "          Acne Infantile    0.96471   0.97619   0.97041        84\n",
      "        Acne Open Comedo    1.00000   1.00000   1.00000        72\n",
      "            Acne Steroid    0.99200   1.00000   0.99598       124\n",
      "         Acne conglobata    0.93617   0.93617   0.93617        47\n",
      "           Acne excoriée    1.00000   1.00000   1.00000        50\n",
      "          Acne fulminans    1.00000   0.83333   0.90909        36\n",
      "  Acne keloidalis nuchae    1.00000   1.00000   1.00000       118\n",
      "           Acne vulgaris    0.96901   0.98286   0.97589       350\n",
      "Hidradenitis suppurativa    0.97619   0.97619   0.97619       168\n",
      "           Hyperhidrosis    0.97222   0.97222   0.97222        36\n",
      "                   Milia    0.96373   0.96373   0.96373       193\n",
      "Minocycline Pigmentation    1.00000   0.93478   0.96629        46\n",
      "           Neonatal acne    1.00000   0.85294   0.92063        34\n",
      "       Occupational acne    1.00000   0.83333   0.90909        12\n",
      "     Perioral Dermatitis    0.94526   0.98479   0.96462       263\n",
      "             Pomade acne    0.90909   1.00000   0.95238        20\n",
      "                 Rosacea    0.98673   0.97380   0.98022       458\n",
      "\n",
      "                accuracy                        0.97480      2381\n",
      "               macro avg    0.97719   0.95566   0.96504      2381\n",
      "            weighted avg    0.97520   0.97480   0.97466      2381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    test_filenames, test_labels = read_directory()\n",
    "    test_tfrecord = 'XRay_test.tfrecords'\n",
    "    build_test_tfrecord(test_filenames, test_labels)\n",
    "\n",
    "\n",
    "    test_dataset = get_test_dataset(test_tfrecord)\n",
    "\n",
    "\n",
    "\n",
    "    test_dataset = data_Preprocessing(test_dataset) \n",
    "\n",
    "    test_labels, predIdxs,prob, Model = test(test_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75caea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dermai_accuracy(prob, prob_Desicon):\n",
    "    dermai = []\n",
    "    for i in range(len(prob)):\n",
    "        catogery =[]\n",
    "        for j in range(len(prob[i])):\n",
    "            if prob[i][j] > prob_Desicon:\n",
    "                catogery.append(j)\n",
    "        dermai.append(catogery)\n",
    "    Positive = []\n",
    "    for i in range(len(dermai)):\n",
    "        if test_labels[i] in dermai[i]:\n",
    "            Positive.append(1)\n",
    "    accuracy = (len(Positive)/len(test_labels))*100  \n",
    "    return  accuracy,dermai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c0d5ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy,dermai = dermai_accuracy(prob, 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97a58752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.23603527929441"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fab93a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
